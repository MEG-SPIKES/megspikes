{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Manual Pipeline\n",
    "\n",
    "In the previous notebook `0_simulation.ipynb` we simulated dataset. Our simulated dataset includes __detections__ and __resection_mni__. Now we are ready to run `Manual detections pipeline` using __detections__ as manually selected spikes and compare the outlut to the __resection_mni__ (ground truth). In this notebook we have the following goals:\n",
    "1. Prepare and run irritative zone delineation using __detections__ timepoints.\n",
    "2. Evaluate the quality of the irritative zone prediction using __resection__.\n",
    "\n",
    "We will use the results presented in this nodebook as a baseline for the automated pipelines.\n",
    "\n",
    "NOTE: To import the megspikes modules we should change the working directory if we are running this example from the cloned GitHub repository."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "# change to the root directory of the project\n",
    "if os.getcwd().split(\"/\")[-1] == \"examples\":\n",
    "    os.chdir('..')\n",
    "\n",
    "from megspikes.simulation.simulation import Simulation\n",
    "\n",
    "# Setup the path for the simulation\n",
    "sample_path = Path(os.getcwd()) / 'examples' / 'data' / '1_manual_pipeline'\n",
    "sample_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the simulation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sim = Simulation(sample_path, n_events=[15, 15, 0, 0])\n",
    "sim.simulate_dataset()\n",
    "sim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`sim.detections` is an array of spike peak localizations in samples. We will use it as manual detections."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sim.detections"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`sim.clusters` is an array of clusters that corresponds to the simulation source index."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sim.clusters"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Manual Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from megspikes.pipeline import iz_prediction_pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\n",
    "    'PrepareClustersDataset': {'detection_sfreq': 1000.}\n",
    "}\n",
    "pipe = iz_prediction_pipeline(sim.case_manager, params)\n",
    "pipe"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "detections = {\n",
    "    'spikes': sim.detections,\n",
    "    'clusters': sim.clusters - 1\n",
    "}\n",
    "dataset, meg_data = pipe.fit_transform((detections, sim.raw_simulation.copy()))"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`dataset` is an instance of xarray.Dataset, and it includes all the results. We can explore the results and the corresponding metadata."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View localized cluster\n",
    "\n",
    "First we should convert numpy ndarray to mne.SourceEstimate. We use `array_to_stc` for this."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from megspikes.localization.localization import array_to_stc\n",
    "\n",
    "stc = array_to_stc(dataset.mne_localization.values[0, 0, :, :],\n",
    "                   sim.case_manager.fwd['ico5'],\n",
    "                   sim.case_manager.case)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can plot the cluster."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib qt5\n",
    "brain = stc.plot(subjects_dir=sim.case_manager.freesurfer_dir, hemi='both')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View clusters using Cluster Slope Viewer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib qt5\n",
    "import mne\n",
    "from megspikes.visualization.visualization import ClusterSlopeViewer\n",
    "mne.viz.set_3d_backend('pyvista')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pc = ClusterSlopeViewer(dataset, sim.case_manager)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pc.view()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's load the updated dataset to check it."
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import xarray as xr\n",
    "updated_ds = xr.load_dataset(pc.fname_save_ds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Veiw IZ prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from megspikes.localization.localization import array_to_stc\n",
    "stc = array_to_stc(dataset.iz_prediction.values[:, -1],\n",
    "                   sim.case_manager.fwd['ico5'],\n",
    "                   sim.case_manager.case)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib qt5\n",
    "\n",
    "# Add function from visualization \n",
    "brain = stc.plot(subjects_dir=sim.case_manager.freesurfer_dir, hemi='both')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate Irritative Zone prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from megspikes.scoring.scoring import ScoreIZPrediction\n",
    "scorer = ScoreIZPrediction()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scorer.score(dataset, sim.mni_resection, 'peak')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot resection and prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "from nilearn import plotting\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "display = plotting.plot_glass_brain(\n",
    "            None, display_mode='lzry', figure=fig, axes=ax)\n",
    "\n",
    "display.add_markers(scorer.detection_mni, marker_color='tomato', alpha=0.2)\n",
    "display.add_markers(sim.mni_resection, marker_color='indigo', alpha=0.6)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test noise levels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params = {\n",
    "    'PrepareClustersDataset': {'detection_sfreq': 1000.}\n",
    "}\n",
    "detections = {\n",
    "    'spikes': sim.detections,\n",
    "    'clusters': sim.clusters - 1\n",
    "}\n",
    "\n",
    "for noise in [0.5, 1, 2, 5, 10]:\n",
    "    sim.simulate_dataset(noise_scaler=noise)\n",
    "    pipe = iz_prediction_pipeline(sim.case_manager, params)\n",
    "    dataset, _ = pipe.fit_transform((detections, sim.raw_simulation.copy()))\n",
    "    baseline_score = scorer.score(dataset, sim.mni_resection, 'baseline')\n",
    "    slope_score = scorer.score(dataset, sim.mni_resection, 'slope')\n",
    "    peak_score = scorer.score(dataset, sim.mni_resection, 'peak')\n",
    "    print(f\"Scores: baseline={baseline_score}, slope={slope_score}, peak={peak_score}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('meg': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd088cc9035523eff0467ba4e14b04b14c109e54066ba0ed0b97ba61e29b1b30bdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}