{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc2d62c",
   "metadata": {},
   "source": [
    "## Manual Pipeline\n",
    "\n",
    "In the previous notebook `0_simulation.ipynb` we simulated a dataset. Our simulated dataset includes __detections__ and __resection_mni__. Now we are ready to run `Manual detections pipeline` using __detections__ as manually selected spikes and compare the output to the __resection_mni__ (ground truth). In this notebook we have the following goals:\n",
    "1. to prepare and run irritative zone delineation using __detections__ timepoints;\n",
    "2. to evaluate the quality of the irritative zone prediction using __resection__.\n",
    "\n",
    "We will use the results presented in this notebook as a baseline for the automated pipelines.\n",
    "\n",
    "NOTE: To import `simulation` the working directory should be changed if the example is run from the cloned GitHub repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e878cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "# change to the root directory of the project\n",
    "if os.getcwd().split(\"/\")[-1] == \"examples\":\n",
    "    os.chdir('..')\n",
    "\n",
    "from megspikes.simulation.simulation import Simulation\n",
    "\n",
    "# Setup the path for the simulation\n",
    "sample_path = Path(os.getcwd()) / 'examples' / 'data' / '1_manual_pipeline'\n",
    "sample_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90503f93",
   "metadata": {},
   "source": [
    "## Prepare the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71274a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Simulation(sample_path, n_events=[15, 15, 0, 0])\n",
    "sim.simulate_dataset()\n",
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f19b1b",
   "metadata": {},
   "source": [
    "`sim.detections` is an array of spike peak localizations in samples. We will use it as manual detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7070396",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1393e1",
   "metadata": {},
   "source": [
    "`sim.clusters` is an array of clusters that corresponds to the simulation source index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c2c81",
   "metadata": {},
   "source": [
    "## Run Manual Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5deb890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megspikes.pipeline import iz_prediction_pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed62dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'PrepareClustersDataset': {'detection_sfreq': 1000.}\n",
    "}\n",
    "pipe = iz_prediction_pipeline(sim.case_manager, params)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3a4ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detections = {\n",
    "    'spikes': sim.detections,\n",
    "    'clusters': sim.clusters - 1\n",
    "}\n",
    "dataset, meg_data = pipe.fit_transform((detections, sim.raw_simulation.copy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730a6ac",
   "metadata": {},
   "source": [
    "`dataset` is an instance of xarray.Dataset, and it includes all the results. Now we can explore the results and the corresponding metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e9e5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf776cc",
   "metadata": {},
   "source": [
    "## View localized cluster\n",
    "\n",
    "First we should convert numpy ndarray to `mne.SourceEstimate`. We use `array_to_stc` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe6e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megspikes.localization.localization import array_to_stc\n",
    "\n",
    "stc = array_to_stc(dataset.mne_localization.values[0, 0, :, :],\n",
    "                   sim.case_manager.fwd['ico5'],\n",
    "                   sim.case_manager.case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4fc3d4",
   "metadata": {},
   "source": [
    "Now we can plot the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "brain = stc.plot(subjects_dir=sim.case_manager.freesurfer_dir, hemi='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef04e22",
   "metadata": {},
   "source": [
    "## View clusters using Cluster Slope Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "import mne\n",
    "from megspikes.visualization.visualization import ClusterSlopeViewer\n",
    "mne.viz.set_3d_backend('pyvista')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2bb5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = ClusterSlopeViewer(dataset, sim.case_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8522cc7",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "We load the updated dataset to check that the dataset has been properly updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "updated_ds = xr.load_dataset(pc.fname_save_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b67772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42573126",
   "metadata": {},
   "source": [
    "## Veiw IZ prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megspikes.localization.localization import array_to_stc\n",
    "stc = array_to_stc(dataset.iz_prediction.values[:, -1],\n",
    "                   sim.case_manager.fwd['ico5'],\n",
    "                   sim.case_manager.case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "\n",
    "surfer_kwargs = dict(\n",
    "    hemi='both',  surface='inflated',  spacing='ico4',\n",
    "    colorbar=False, background='w', foreground='k',\n",
    "    colormap='Reds', smoothing_steps=10, alpha=1,\n",
    "    add_data_kwargs={\"fmin\": 0, \"fmid\": 0.5, \"fmax\": 0.8})\n",
    "brain = stc.plot(subjects_dir=sim.case_manager.freesurfer_dir, **surfer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7213309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a079dc1",
   "metadata": {},
   "source": [
    "## Evaluate Irritative Zone prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megspikes.scoring.scoring import ScoreIZPrediction\n",
    "scorer = ScoreIZPrediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768d940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist = scorer.score(dataset, sim.mni_resection, 'peak')\n",
    "print(f\"Average distance from the resection area is {dist:.0f} mm for the 'peak' condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9950d3",
   "metadata": {},
   "source": [
    "### Plot resection and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nilearn import plotting\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "display = plotting.plot_glass_brain(\n",
    "            None, display_mode='lzry', figure=fig, axes=ax)\n",
    "\n",
    "display.add_markers(scorer.detection_mni, marker_color='tomato', alpha=0.2)\n",
    "display.add_markers(sim.mni_resection, marker_color='indigo', alpha=0.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a3bed5",
   "metadata": {},
   "source": [
    "## Test noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'PrepareClustersDataset': {'detection_sfreq': 1000.}\n",
    "}\n",
    "detections = {\n",
    "    'spikes': sim.detections,\n",
    "    'clusters': sim.clusters - 1\n",
    "}\n",
    "\n",
    "for noise in [0.5, 1, 2, 5, 10]:\n",
    "    sim.simulate_dataset(noise_scaler=noise)\n",
    "    pipe = iz_prediction_pipeline(sim.case_manager, params)\n",
    "    dataset, _ = pipe.fit_transform((detections, sim.raw_simulation.copy()))\n",
    "    baseline_score = scorer.score(dataset, sim.mni_resection, 'baseline')\n",
    "    slope_score = scorer.score(dataset, sim.mni_resection, 'slope')\n",
    "    peak_score = scorer.score(dataset, sim.mni_resection, 'peak')\n",
    "    print(f\"Scores: baseline={baseline_score}, slope={slope_score}, peak={peak_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60980002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('meg': conda)",
   "language": "python",
   "name": "python3710jvsc74a57bd088cc9035523eff0467ba4e14b04b14c109e54066ba0ed0b97ba61e29b1b30bdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
